{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "### APIs\n",
    "import tweepy\n",
    "\n",
    "## Plots\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sea\n",
    "get_ipython().magic('matplotlib inline')\n",
    "\n",
    "# Sentiment analysis\n",
    "from textblob import TextBlob\n",
    "import re, os, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.getcwd(),\"data/credentials.json\")) as data_file:    \n",
    "    key = json.load(data_file)\n",
    "\n",
    "#print key[\"API_KEY\"], key[\"API_SECRET\"], key[\"ACCESS_TOKEN\"], key[\"ACCESS_TOKEN_SECRET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_setup():\n",
    "    #authentication\n",
    "    auth = tweepy.OAuthHandler(key[\"API_KEY\"], key[\"API_SECRET\"])\n",
    "    auth.set_access_token(key[\"ACCESS_TOKEN\"], key[\"ACCESS_TOKEN_SECRET\"])    \n",
    "    return tweepy.API(auth)\n",
    "\n",
    "extractor = twitter_setup()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = extractor.user_timeline(screen_name=\"cdvel\", count=100)\n",
    "print (\"No. tweets extracted: {}\\n\".format(len(tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Latest 5 tweets\")\n",
    "for tweet in tweets[:5]:\n",
    "    print (tweet.text)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data=[tweet.text for tweet in tweets], columns=['Tweets'])\n",
    "data['length']  = np.array([len(tweet.text) for tweet in tweets])\n",
    "data['id']   = np.array([tweet.id for tweet in tweets])\n",
    "data['created'] = np.array([tweet.created_at for tweet in tweets])\n",
    "data['source'] = np.array([tweet.source for tweet in tweets])\n",
    "data['no_likes'] = np.array([tweet.favorite_count for tweet in tweets])\n",
    "data['no_retweets'] = np.array([tweet.retweet_count for tweet in tweets])\n",
    "data['slug'] = np.array([''.join([tweet.user.screen_name, '/status/', str(tweet.id)])  for tweet in tweets])\n",
    "\n",
    "\n",
    "#print tweet\n",
    "display(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_length = np.mean(data['length'])\n",
    "\n",
    "print(\"Tweet's avg length: {}\".format(mean_length))\n",
    "\n",
    "likes_max = np.max(data['no_likes'])\n",
    "retweets_max = np.max(data['no_retweets'])\n",
    "\n",
    "most_likes = data[data.no_likes == likes_max].index[0]\n",
    "most_retweets = data[data.no_retweets == retweets_max].index[0]\n",
    "\n",
    "print (\"\\nMost liked: \\n> {} length={} ♡={}\".format(data['Tweets'][most_likes].encode('utf-8'), data['length'][most_likes], likes_max))\n",
    "print (\"\\nMost retweeted: \\n> {} length={} RTs={}\".format(data['Tweets'][most_retweets].encode('utf-8'), data['length'][most_retweets], retweets_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_length = pd.Series(data=data['length'].values, index=data['created'])\n",
    "series_likes  = pd.Series(data=data['no_likes'].values, index=data['created'])\n",
    "series_retweets = pd.Series(data=data['no_retweets'].values, index=data['created'])\n",
    "\n",
    "series_length.plot(figsize=(16,4), color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_likes.plot(figsize=(16,4), label='Likes', legend=True)\n",
    "series_retweets.plot(figsize=(16,4), label='Retweets', legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sources = []\n",
    "for source in data['source']:\n",
    "    all_sources.append(str(source))\n",
    "\n",
    "all_sources = list(set(all_sources))    \n",
    "print(\"Sources: {}\".format(all_sources))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = np.zeros(len(all_sources))\n",
    "\n",
    "for src in data['source']:\n",
    "    percent[all_sources.index(src)] += 1\n",
    "\n",
    "percent /= 100\n",
    "\n",
    "pie_chart = pd.Series(percent, index=all_sources, name='sources')\n",
    "pie_chart.plot.pie(fontsize=11, autopct='%.2f', figsize=(6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def analyse(tweet):\n",
    "    analysis = TextBlob(tweet)\n",
    "    return  1 if analysis.polarity > 0 else 0 if analysis.polarity == 0 else -1\n",
    "\n",
    "data['sentiment'] = np.array([analyse(tweet) for tweet in data['Tweets']])\n",
    "\n",
    "display(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = [tweet for index, tweet in enumerate(data['Tweets']) if data['sentiment'][index] > 0]\n",
    "neutral   = [tweet for index, tweet in enumerate(data['Tweets']) if data['sentiment'][index] == 0]\n",
    "negatives = [tweet for index, tweet in enumerate(data['Tweets']) if data['sentiment'][index] < 0]\n",
    "\n",
    "print(\"👍: {}, 👎: {}, 😐: {} \". format(len(positives), len(negatives), len(neutral)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### References \n",
    "- https://github.com/avisaxena33/Twitter-Data-Sentiment-Analysis-with-Python-Workshop/blob/master/twitter.py\n",
    "\n",
    "### Notes\n",
    "oauthlib, textblob for OSX64\n",
    "- https://anaconda.org/asmeurer/oauthlib\n",
    "- https://anaconda.org/sloria/textblob\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
